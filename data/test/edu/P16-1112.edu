In this paper , we present the first experiments 
using neural network models for the task of error detection in learner writing . <S>
We perform a systematic comparison of alternative compositional architectures 
and propose a framework for error detection 
based on bidirectional LSTMs . <S>
Experiments on the CoNLL-14 shared task dataset show 
the model is able to outperform other participants 
on detecting errors in learner writing . <S>
Finally , the model is integrated with a publicly deployed self-assessment system , 
leading to performance 
comparable to human annotators . <S>
