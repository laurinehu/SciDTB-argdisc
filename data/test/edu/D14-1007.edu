This paper proposes a Markov Decision Process and reinforcement learning based approach for domain selection in a multi-domain Spoken Dialogue System 
built on a distributed architecture . <S>
In the proposed framework , the domain selection problem is treated as sequential planning instead of classification , 
such that confirmation and clarification interaction mechanisms are supported . <S>
In addition , it is shown 
that by using a model parameter tying trick , 
the extensibility of the system can be preserved , 
where dialogue components in new domains can be easily plugged in , 
without re-training the domain selection policy . <S>
The experimental results 
based on human subjects 
suggest 
that the proposed model marginally outperforms a non-trivial baseline . <S>
