State-of-the-art semantic role labelling systems require large annotated corpora 
to achieve full performance . <S>
Unfortunately , such corpora are expensive to produce 
and often do not generalize well across do-mains . <S>
Even in domain , errors are often made 
where syntactic information does not provide sufficient cues . <S>
In this paper , we mitigate both of these problems 
by employing distributional word representations 
gathered from unlabelled data . <S>
While straight-forward word representations of predicates and arguments improve performance , 
we show 
that further gains are achieved 
by composing representations 
that model the interaction between predicate and argument , 
and capture full argument spans . <S>
