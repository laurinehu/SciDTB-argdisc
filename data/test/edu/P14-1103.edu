We present a method 
to jointly learn features and weights directly from distributional data in a log-linear framework . <S>
Specifically , we propose a non-parametric Bayesian model 
for learning phonological markedness constraints directly from the distribution of input-output mappings in an Optimality Theory ( OT ) setting . <S>
The model uses an Indian Buffet Process 
prior to learn the feature values 
used in the log-linear method , 
and is the first algorithm 
for learning phonological constraints 
without presupposing constraint structure . <S>
The model learns a system of constraints 
that explains observed data as well as the phonologically-grounded constraints of a standard analysis , with a violation structure 
corresponding to the standard constraints . <S>
These results suggest an alternative data-driven source for constraints instead of a fully innate constraint set . <S>
