In this paper , we propose a novel neural network model 
called RNN Encoder- Decoder 
that consists of two recurrent neural networks ( RNN ) . <S>
One RNN encodes a sequence of symbols into a fixed-length vector representation , 
and the other decodes the representation into another sequence of symbols . <S>
The encoder and decoder of the proposed model are jointly trained 
to maximize the conditional probability of a target sequence 
given a source sequence . <S>
The performance of a statistical machine translation system is empirically found to improve 
by using the conditional probabilities of phrase pairs 
computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model . <S>
Qualitatively , we show 
that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases . <S>
