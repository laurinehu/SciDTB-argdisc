This work presents two different translation models 
using recurrent neural networks . <S>
The first one is a word-based approach 
using word alignments . <S>
Second , we present phrase-based translation models 
that are more consistent with phrase-based decoding . <S>
Moreover , we introduce bidirectional recurrent neural models to the problem of machine translation , 
allowing us to use the full source sentence in our models , 
which is also of theoretical interest . <S>
We demonstrate 
that our translation models are capable of improving strong baselines 
already including recurrent neural language models on three tasks : 
IWSLT 2013 German to English , BOLT Arabic to English and Chinese to English . <S>
We obtain gains up to 1.6 % BLEU and 1.7 % TER 
by rescoring 1000-best lists . <S>
