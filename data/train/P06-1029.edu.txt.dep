{
	"root": [
		{
			"id": 0,
			"parent": -1,
			"text": "ROOT",
			"relation": "null"
		},
		{
			"id": 1,
			"parent": 3,
			"text": "Lasso is a regularization method for parameter estimation in linear models . <S>",
			"relation": "bg-goal"
		},
		{
			"id": 2,
			"parent": 1,
			"text": "It optimizes the model parameters with respect to a loss function subject to model complexities . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 3,
			"parent": 0,
			"text": "This paper explores the use of lasso for statistical language modeling for text input . <S>",
			"relation": "ROOT"
		},
		{
			"id": 4,
			"parent": 5,
			"text": "Owing to the very large number of parameters , ",
			"relation": "exp-reason"
		},
		{
			"id": 5,
			"parent": 6,
			"text": "directly optimizing the penalized lasso loss function is impossible . <S>",
			"relation": "result"
		},
		{
			"id": 6,
			"parent": 3,
			"text": "Therefore , we investigate two approximation methods , ",
			"relation": "elab-addition"
		},
		{
			"id": 7,
			"parent": 6,
			"text": "the boosted lasso ( BLasso ) and the forward stagewise linear regression ( FSLR ) . <S>",
			"relation": "elab-enum_member"
		},
		{
			"id": 8,
			"parent": 6,
			"text": "Both methods , ",
			"relation": "elab-addition"
		},
		{
			"id": 9,
			"parent": 8,
			"text": "when used with the exponential loss function , ",
			"relation": "condition"
		},
		{
			"id": 10,
			"parent": 8,
			"text": "bear strong resemblance to the boosting algorithm ",
			"relation": "same-unit"
		},
		{
			"id": 11,
			"parent": 10,
			"text": "which has been used as a discriminative training method for language modeling . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 12,
			"parent": 13,
			"text": "Evaluations on the task of Japanese text input show ",
			"relation": "attribution"
		},
		{
			"id": 13,
			"parent": 3,
			"text": "that BLasso is able to produce the best approximation to the lasso solution , ",
			"relation": "evaluation"
		},
		{
			"id": 14,
			"parent": 13,
			"text": "and leads to a significant improvement , in terms of character error rate , over boosting and the traditional maximum likelihood estimation . <S>",
			"relation": "joint"
		}
	]
}