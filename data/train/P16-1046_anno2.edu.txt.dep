{
	"root": [
		{
			"id": 0,
			"parent": -1,
			"text": "ROOT",
			"relation": "null"
		},
		{
			"id": 1,
			"parent": 2,
			"text": "Traditional approaches to extractive summarization rely heavily on humanengineered features . <S>",
			"relation": "bg-compare"
		},
		{
			"id": 2,
			"parent": 0,
			"text": "In this work we propose a data-driven approach ",
			"relation": "ROOT"
		},
		{
			"id": 3,
			"parent": 2,
			"text": "based on neural networks and continuous sentence features . <S>",
			"relation": "bg-general"
		},
		{
			"id": 4,
			"parent": 2,
			"text": "We develop a general framework for single-document summarization ",
			"relation": "elab-addition"
		},
		{
			"id": 5,
			"parent": 4,
			"text": "composed of a hierarchical document encoder and an attention-based extractor . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 6,
			"parent": 4,
			"text": "This architecture allows us to develop different classes of summarization models ",
			"relation": "elab-addition"
		},
		{
			"id": 7,
			"parent": 6,
			"text": "which can extract sentences or words . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 8,
			"parent": 4,
			"text": "We train our models on large scale corpora ",
			"relation": "elab-addition"
		},
		{
			"id": 9,
			"parent": 8,
			"text": "containing hundreds of thousands of document-summary pairs1 . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 10,
			"parent": 11,
			"text": "Experimental results on two summarization datasets demonstrate ",
			"relation": "attribution"
		},
		{
			"id": 11,
			"parent": 2,
			"text": "that our models obtain results comparable to the state of the art ",
			"relation": "evaluation"
		},
		{
			"id": 12,
			"parent": 11,
			"text": "without any access to linguistic annotation . <S>",
			"relation": "elab-addition"
		}
	]
}