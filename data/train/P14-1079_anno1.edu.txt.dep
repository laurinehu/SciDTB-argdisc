{
	"root": [
		{
			"id": 0,
			"parent": -1,
			"text": "ROOT",
			"relation": "null"
		},
		{
			"id": 1,
			"parent": 3,
			"text": "The essence of distantly supervised relation extraction is that it is an incomplete multi-label classification problem with sparse and noisy features . <S>\r",
			"relation": "bg-goal"
		},
		{
			"id": 2,
			"parent": 3,
			"text": "To tackle the sparsity and noise challenges , \r",
			"relation": "enablement"
		},
		{
			"id": 3,
			"parent": 0,
			"text": "we propose solving the classification problem \r",
			"relation": "ROOT"
		},
		{
			"id": 4,
			"parent": 3,
			"text": "using matrix completion on factorized matrix of minimized rank . <S>\r",
			"relation": "manner-means"
		},
		{
			"id": 5,
			"parent": 3,
			"text": "We formulate relation classification as completing the unknown labels of testing items \r",
			"relation": "elab-aspect"
		},
		{
			"id": 6,
			"parent": 5,
			"text": "( entity pairs ) \r",
			"relation": "elab-addition"
		},
		{
			"id": 7,
			"parent": 5,
			"text": "in a sparse matrix \r",
			"relation": "same-unit"
		},
		{
			"id": 8,
			"parent": 7,
			"text": "that concatenates training and testing textual features with training labels . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 9,
			"parent": 11,
			"text": "Our algorithmic framework is based on the assumption \r",
			"relation": "result"
		},
		{
			"id": 10,
			"parent": 9,
			"text": "that the rank of item-by-feature and item-by-label joint matrix is low . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 11,
			"parent": 3,
			"text": "We apply two optimization models \r",
			"relation": "elab-aspect"
		},
		{
			"id": 12,
			"parent": 11,
			"text": "to recover the underlying low-rank matrix \r",
			"relation": "enablement"
		},
		{
			"id": 13,
			"parent": 11,
			"text": "leveraging the sparsity of feature-label matrix . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 14,
			"parent": 3,
			"text": "The matrix completion problem is then solved by the fixed point continuation ( FPC ) algorithm , \r",
			"relation": "elab-aspect"
		},
		{
			"id": 15,
			"parent": 14,
			"text": "which can find the global optimum . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 16,
			"parent": 17,
			"text": "Experiments on two widely used datasets with different dimensions of textual features demonstrate \r",
			"relation": "attribution"
		},
		{
			"id": 17,
			"parent": 3,
			"text": "that our low-rank matrix completion approach significantly outperforms the baseline and the state-of-the-art methods . <S>\r",
			"relation": "evaluation"
		}
	]
}