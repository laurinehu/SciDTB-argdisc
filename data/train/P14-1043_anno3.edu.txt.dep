{
	"root": [
		{
			"id": 0,
			"parent": -1,
			"text": "ROOT",
			"relation": "null"
		},
		{
			"id": 1,
			"parent": 0,
			"text": "This paper proposes a simple yet effective framework for semi-supervised dependency parsing at entire tree level , \r",
			"relation": "ROOT"
		},
		{
			"id": 2,
			"parent": 1,
			"text": "referred to as ambiguity-aware ensemble training . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 3,
			"parent": 4,
			"text": "Instead of only using 1-best parse trees in previous work , \r",
			"relation": "contrast"
		},
		{
			"id": 4,
			"parent": 1,
			"text": "our core idea is to utilize parse forest ( ambiguous labelings ) \r",
			"relation": "elab-aspect"
		},
		{
			"id": 5,
			"parent": 4,
			"text": "to combine multiple 1-best parse trees \r",
			"relation": "enablement"
		},
		{
			"id": 6,
			"parent": 5,
			"text": "generated from diverse parsers on unlabeled data . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 7,
			"parent": 8,
			"text": "With a conditional random field based probabilistic dependency parser , \r",
			"relation": "condition"
		},
		{
			"id": 8,
			"parent": 1,
			"text": "our training objective is to maximize mixed likelihood of labeled data and auto-parsed unlabeled data with ambiguous labelings . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 9,
			"parent": 8,
			"text": "This framework offers two promising advantages . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 10,
			"parent": 9,
			"text": "1 ) ambiguity encoded in parse forests compromises noise in 1-best parse trees . <S>\r",
			"relation": "elab-aspect"
		},
		{
			"id": 11,
			"parent": 12,
			"text": "During training , \r",
			"relation": "temporal"
		},
		{
			"id": 12,
			"parent": 10,
			"text": "the parser is aware of these ambiguous structures , \r",
			"relation": "elab-addition"
		},
		{
			"id": 13,
			"parent": 12,
			"text": "and has the flexibility \r",
			"relation": "progression"
		},
		{
			"id": 14,
			"parent": 13,
			"text": "to distribute probability mass to its preferred parse trees \r",
			"relation": "enablement"
		},
		{
			"id": 15,
			"parent": 14,
			"text": "as long as the likelihood improves . <S>\r",
			"relation": "condition"
		},
		{
			"id": 16,
			"parent": 9,
			"text": "2 ) diverse syntactic structures \r",
			"relation": "elab-aspect"
		},
		{
			"id": 17,
			"parent": 16,
			"text": "produced by different parsers \r",
			"relation": "elab-addition"
		},
		{
			"id": 18,
			"parent": 16,
			"text": "can be naturally compiled into forest , \r",
			"relation": "same-unit"
		},
		{
			"id": 19,
			"parent": 18,
			"text": "offering complementary strength to our single-view parser . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 20,
			"parent": 21,
			"text": "Experimental results on benchmark data show \r",
			"relation": "attribution"
		},
		{
			"id": 21,
			"parent": 1,
			"text": "that our method significantly outperforms the baseline supervised parser and other entire-tree based semi-supervised methods , such as self-training , co-training and tri-training . <S>\r",
			"relation": "evaluation"
		}
	]
}