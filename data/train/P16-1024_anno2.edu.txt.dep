{
	"root": [
		{
			"id": 0,
			"parent": -1,
			"text": "ROOT",
			"relation": "null"
		},
		{
			"id": 1,
			"parent": 2,
			"text": "A shared bilingual word embedding space ( SBWES ) is an indispensable resource in a variety of cross-language NLP and IR tasks . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 2,
			"parent": 8,
			"text": "A common approach to the SBWES induction is to learn a mapping function between monolingual semantic spaces , ",
			"relation": "bg-compare"
		},
		{
			"id": 3,
			"parent": 2,
			"text": "where the mapping critically relies on a seed word lexicon ",
			"relation": "elab-addition"
		},
		{
			"id": 4,
			"parent": 3,
			"text": "used in the learning process . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 5,
			"parent": 7,
			"text": "In this work , we analyze the importance and properties of seed lexicons for the SBWES induction across different dimensions ",
			"relation": "elab-addition"
		},
		{
			"id": 6,
			"parent": 5,
			"text": "( i.e. , lexicon source , lexicon size , translation method , translation pair reliability ) . <S>",
			"relation": "elab-example"
		},
		{
			"id": 7,
			"parent": 8,
			"text": "On the basis of our analysis , ",
			"relation": "bg-general"
		},
		{
			"id": 8,
			"parent": 0,
			"text": "we propose a simple but effective hybrid bilingual word embedding ( BWE ) model . <S>",
			"relation": "ROOT"
		},
		{
			"id": 9,
			"parent": 8,
			"text": "This model ( HYBWE ) learns the mapping between two monolingual embedding spaces ",
			"relation": "elab-addition"
		},
		{
			"id": 10,
			"parent": 9,
			"text": "using only highly reliable symmetric translation pairs from a seed document-level embedding space . <S>",
			"relation": "manner-means"
		},
		{
			"id": 11,
			"parent": 14,
			"text": "We perform bilingual lexicon learning ( BLL ) with 3 language pairs ",
			"relation": "progression"
		},
		{
			"id": 12,
			"parent": 14,
			"text": "and show ",
			"relation": "attribution"
		},
		{
			"id": 13,
			"parent": 14,
			"text": "that by carefully selecting reliable translation pairs ",
			"relation": "manner-means"
		},
		{
			"id": 14,
			"parent": 8,
			"text": "our new HYBWE model outperforms benchmarking BWE learning models , ",
			"relation": "evaluation"
		},
		{
			"id": 15,
			"parent": 14,
			"text": "all of which use more expensive bilingual signals . <S>",
			"relation": "elab-addition"
		},
		{
			"id": 16,
			"parent": 17,
			"text": "Effectively , we demonstrate ",
			"relation": "attribution"
		},
		{
			"id": 17,
			"parent": 8,
			"text": "that a SBWES may be induced ",
			"relation": "summary"
		},
		{
			"id": 18,
			"parent": 17,
			"text": "by leveraging only a very weak bilingual signal ( document alignments ) along with monolingual data . <S>  ",
			"relation": "manner-means"
		}
	]
}