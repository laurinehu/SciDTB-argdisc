Unlike traditional over-the-phone spoken dialog systems ( SDSs ) , 
modern dialog systems tend to have visual rendering on the device screen as an additional modality 
to communicate the system's response to the user . <S>
Visual display of the system's response not only changes human behavior 
when interacting with devices , 
but also creates new research areas in SDSs . <S>
On-screen item identification and resolution in utterances is one critical problem 
to achieve a natural and accurate human-machine communication . <S>
We pose the problem as a classification task 
to correctly identify intended on-screen item ( s ) from user utterances . <S>
Using syntactic , semantic as well as context features from the display screen , 
our model can resolve different types of referring expressions with up to 90 % accuracy . <S>
In the experiments we also show 
that the proposed model is robust to domain and screen layout changes . <S>
