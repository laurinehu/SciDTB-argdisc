Automatically generating a natural language description of an image is a fundamental problem in artificial intelligence . <S>
This task involves both computer vision and natural language processing 
and is called `` image caption generation . '' <S> 
Research on image caption generation has typically focused on taking in an image 
and generating a caption in English 
as existing image caption corpora are mostly in English . <S>
The lack of corpora in languages other than English is an issue , especially for morphologically rich languages such as Japanese . <S>
There is thus a need for corpora sufficiently large for image captioning in other languages . <S>
We have developed a Japanese version of the MS COCO caption dataset and a generative model 
based on a deep recurrent architecture 
that takes in an image 
and uses this Japanese version of the dataset 
to generate a caption in Japanese . <S>
As the Japanese portion of the corpus is small , 
our model was designed 
to transfer the knowledge representation 
obtained from the English portion 
into the Japanese portion . <S>
Experiments showed 
that the resulting bilingual comparable corpus has better performance than a monolingual corpus , 
indicating 
that image understanding 
using a resource-rich language 
benefits a resource-poor language . <S>
