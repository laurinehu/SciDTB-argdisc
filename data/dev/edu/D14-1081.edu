We propose the first implementation of an infinite-order generative dependency model . <S>
The model is based on a new recursive neural network architecture , the Inside-Outside Recursive Neural Network . <S>
This architecture allows information to flow not only bottom-up , as in traditional recursive neural networks , but also top-down . <S>
This is achieved 
by computing content as well as context representations for any constituent , 
and letting these representations interact . <S>
Experimental results on the English section of the Universal Dependency Treebank show 
that the infinite-order model achieves a perplexity seven times lower than the traditional third-order model 
using counting , 
and tends to choose more accurate parses in k-best lists . <S>
In addition , reranking with this model achieves state-of-the-art unlabelled attachment scores and unlabelled exact match scores . <S>
