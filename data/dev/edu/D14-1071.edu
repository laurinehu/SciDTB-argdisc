Transforming a natural language ( NL ) question into a corresponding logical form ( LF ) is central to the knowledge-based question answering ( KB-QA ) task . <S>
Unlike most previous methods 
that achieve this goal 
based on mappings between lexicalized phrases and logical predicates , 
this paper goes one step further 
and proposes a novel embedding-based approach 
that maps NL-questions into LFs for KB-QA 
by leveraging semantic associations between lexical representations and KB-properties in the latent space . <S>
Experimental results demonstrate 
that our proposed method outperforms three KB-QA baseline methods on two publicly released QA data sets . <S>
