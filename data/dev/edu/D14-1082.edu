Almost all current dependency parsers classify 
based on millions of sparse indicator features . <S>
Not only do these features generalize poorly , 
but the cost of feature computation restricts parsing speed significantly . <S>
In this work , we propose a novel way 
of learning a neural network classifier for use in a greedy , transition-based dependency parser . <S>
Because this classifier learns and uses just a small number of dense features , 
it can work very fast , 
while achiev-ing an about 2 % improvement in unlabeled and labeled attachment scores on both English and Chinese datasets . <S>
Concretely , our parser is able to parse more than 1000 sentences per second at 92.2 % unlabeled attachment score on the English Penn Treebank . <S>
