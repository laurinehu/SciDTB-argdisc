We present a pairwise context-sensitive Autoencoder 
for computing text pair similarity . <S>
Our model encodes input text into context-sensitive representations 
and uses them 
to compute similarity between text pairs . <S>
Our model outperforms the state-of-the-art models in two semantic retrieval tasks and a contextual word similarity task . <S>
For retrieval , our unsupervised approach 
that merely ranks inputs with respect to the cosine similarity between their hidden representations 
shows comparable performance with the state-of-the-art supervised models 
and in some cases outperforms them . <S>   
