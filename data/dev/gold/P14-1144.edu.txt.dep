{
	"root": [
		{
			"id": 0,
			"parent": -1,
			"text": "ROOT",
			"relation": "null"
		},
		{
			"id": 1,
			"parent": 4,
			"text": "Recently , researchers have begun exploring methods \r",
			"relation": "bg-goal"
		},
		{
			"id": 2,
			"parent": 1,
			"text": "of scoring student essays with respect to particular dimensions of quality such as coherence , technical errors , and prompt adherence . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 3,
			"parent": 1,
			"text": "The work on modeling prompt adherence , however , has been focused mainly on whether individual sentences adhere to the prompt . <S>\r",
			"relation": "elab-addition"
		},
		{
			"id": 4,
			"parent": 0,
			"text": "We present a new annotated corpus of essay-level prompt adherence scores \r",
			"relation": "ROOT"
		},
		{
			"id": 5,
			"parent": 4,
			"text": "and propose a feature-rich approach to scoring essays along the prompt adherence dimension . <S>\r",
			"relation": "joint"
		},
		{
			"id": 6,
			"parent": 4,
			"text": "Our approach significantly outperforms a knowledge-lean baseline prompt adherence scoring system \r",
			"relation": "evaluation"
		},
		{
			"id": 7,
			"parent": 6,
			"text": "yielding improvements of up to 16.6 % . <S>\r",
			"relation": "elab-addition"
		}
	]
}
